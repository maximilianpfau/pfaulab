---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Human selection bias drives the linear nature of the more ground truth effect
  in explainable deep learning optical coherence tomography image segmentation
subtitle: ''
summary: ''
authors:
- Peter M Maloca
- Maximilian Pfau
- Lucas Janeschitz-Kriegl
- Michael Reich
- Lukas Goerdt
- Frank G Holz
- Philipp L MÃ¼ller
- Philippe Valmaggia
- Katrin Fasler
- Pearse A Keane
- Javier Zarranz-Ventura
- Sandrine Zweifel
- Jonas Wiesendanger
- Pascal Kaiser
- Tim J Enz
- Simon P Rothenbuehler
- Pascal W Hasler
- Marlene Juedes
- Christian Freichel
- Catherine Egan
- Adnan Tufail
- Hendrik P N Scholl
- Nora Denk
tags:
- Explainable ai; machine learning; optical coherence tomography; retina
categories: []
date: '2024-02-01'
lastmod: 2024-07-19T23:41:30+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2024-07-19T21:41:29.086438Z'
publication_types:
- '2'
abstract: Supervised deep learning (DL) algorithms are highly dependent on training
  data for which human graders are assigned, for example, for optical coherence tomography
  (OCT) image annotation. Despite the tremendous success of DL, due to human judgment,
  these ground truth labels can be inaccurate and/or ambiguous and cause a human selection
  bias. We therefore investigated the impact of the size of the ground truth and variable
  numbers of graders on the predictive performance of the same DL architecture and
  repeated each experiment three times. The largest training dataset delivered a prediction
  performance close to that of human experts. All DL systems utilized were highly
  consistent. Nevertheless, the DL under-performers could not achieve any further
  autonomous improvement even after repeated training. Furthermore, a quantifiable
  linear relationship between ground truth ambiguity and the beneficial effect of
  having a larger amount of ground truth data was detected and marked as the more-ground-truth
  effect.
publication: '*J. Biophotonics*'
---
